Memory allocation

Страница -- 4KB
Ядро ОС -- планировщик, менеджер памяти, .... Большая часть ядра -- драйвера
Интерфейс между ядром и программами: mmap, munmap в nix, VirtualAlloc, VirtualFree.
void* mmap(void* location, size_t size, ...), location -- начало первой страницы,
size -- количество страниц в виртуальной памяти, которые хотим отобразить.
int munmap(void* location, size_t size...) -- результат при успехе 0, при фейле -1,
errornum показывает код ошибки (thread-local переменная)
Эти функции -- интерфейс ядра, в некотором смысле
Если на каждый malloc делать mmap, все будет очень плохо, потому что на каждое 
выделение памяти будет выделяться 4KB. 
Когда ядро выделяет память, оно зануляет страницу, потому что если так не делать,
то можно получить доступ к информации другой программы, память которой только
что освободилась. Поэтому просто 1кк mmap-ов занимает секунду, а 1кк с обращениями
занимает 2.5. При этом 1кк по 1к mmap-ов тоже секунду, а с обращениями 1500. 
Память выделяется лениво, есть flag populate, который может сказать, чтобы
все сразу занулялось. 

Как делать malloc, чтобы он не выделял каждый раз. Пусть сначала объекты 
одного размера, тогда можно просто хранить их подряд на странице. Если они
разного размера, то можно сделать много разных аллокаторов для объектов разного
размера, а потом округлять в большую сторону. Храним список. Как делать free: 
Храним дерево, через которое можно мапить не понял что
Чтобы было удобно, можно хранить чанки по 64KB, а в начале хранить служебную инфу
про то, какого размера куски тут лежат. Это надо, потому что свободные куски
прошиты односвязным списком, и когда память освобождается, надо знать, куда этот
свободный кусок пихать. Когда чанк кончается, просто выделяется еще один и 
его куски памяти прошиваются списком. Указатель на следующую ячейку хранится
просто в свободной ячейке.

Все это работает для маленьких объектов, большие работают по-другому. Можно было
бы хранить два прошитых дерева поиска, одно по адресам, другое по размерам. По
одному идти, когда выделяешь, по другому, когда удаляешь. Хуйня непонятная.

SMALL OBJECT OPTIMIZATION -- вообще типа тема лекции. 
(есть еще copy on write)

Наблюдение: в коротких строках указатель на память занимает почти столько же места,
сколько данные самой строки. 
Можно так: хранить size, ptr, capacity, всего 24б. Если строчка короткая, то на
месте ptr и capacity хранить саму строку, в 16б. Успех, потому что нет такого
большого количества вызовов malloc/free. Вообще работает со всеми объектами, 
можно вместо указателя на данные хранить сами данные, если их немного. 

В коде:

struct string {
	size_t size;
	union {
		dynamic_storage dstorage;
		char sstorage[sizeof(dynamic_storage)];
	};
}

Байка: в стринге было
char& operator[](size_t index) {
	if (size < sizeof(dynamic_storage)) {
		return sstorage[index];
	} else {
		return dstorage.ptr[index];
	}
}

Медленно, потому что, во-первых, вызов функции, во-вторых, есть иф, который
(почему-то) плохо предсказывается. Но больше тратилось на вызов.

COPY ON WRITE

Когда копируем объект, можем сделать так, чтобы копия ссылалась туда же, куда
ссылался изначальный объект, а копируется только при попытке изменить один
из них.
































